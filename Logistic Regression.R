# Install packages
install.packages('Amelia')
library(Amelia)

install.packages('pscl')
library(pscl)

install.packages('gplots')
install.packages('bitops')
library(gplots)

install.packages('ROCR')
library(ROCR)

# Read data
training.data.raw = read.csv('train.csv', header=T, na.strings = c(""))
sapply(training.data.raw, function(x) sum(is.na(x))) # count how many missing values there are for each variable
sapply(training.data.raw, function(x) length(unique(x))) # count how many unique values there are for each variable

# Check missing values
missmap(training.data.raw, main = "Missing values vs observed") # missmap() plots dataset and highlights missing values
names(training.data.raw)
data = subset(training.data.raw, select = c(2, 3, 5, 6, 7, 8, 10, 12)) # keep the variables for LR

# Replace missing values
data$Age[is.na(data$Age)] = mean(data$Age, na.rm = T) # replace the missing values with the average
data = data[!is.na(data$Embarked),] # remove the records with missing values for Embarked since there are only 2
sapply(data, function(x) sum(is.na(x)))

# Format data
is.factor(data$Sex) # check if R by default encodes the categorical variables as factors
is.factor(data$Embarked)
is.factor(data$Survived)
is.factor(data$Pclass)

contrasts(data$Sex) # contrasts() shows how the variables have been dummified by R
contrasts(data$Embarked)

# Code as categorical variables and change labels for levels
data_dsp = data
data_dsp$Survived = factor(data$Survived, levels = c(1,0), labels = c("Survived", "Died"))
data_dsp$Pclass = factor(data$Pclass, levels = c(1,2,3), labels = c("First class", "Second class", "Third class"))
data_dsp$Sex = factor(data$Sex, levels = c("female","male"), labels = c("Female","Male"))

# Create mosaic plots
plot1 = mosaicplot(data_dsp$Pclass ~ data_dsp$Survived, main = "Passenger Survival by Class", color = c("#8dd3c7", "#fb8072"), 
                   shade=FALSE,  xlab="", ylab="",off=c(0), cex.axis=1.4)

plot2 = mosaicplot(data_dsp$Sex ~ data_dsp$Survived, main = "Passenger Survival by Gender", color = c("#8dd3c7", "#fb8072"), 
                   shade=FALSE,  xlab="", ylab="",off=c(0), cex.axis=1.4)

# Logistic regression
sample_size = floor(0.9 * nrow(data))
set.seed(123)
train_ind = sample(seq_len(nrow(data)), size = sample_size) # randomly select 90% of the data as training data
train = data[train_ind,]
test = data[-train_ind,]

model = glm(Survived ~., family = binomial(link = 'logit'), data = train)

# Obtain the results of the model
summary(model) 
# Sex has the lowest p-value suggesting a strong association of the sex of the passenger with the probability of having survived
# Being male reduces the log odds by 2.58 while a unit increase in age reduces the log odds by 0.037.

anova(model, test='Chisq')
# The difference between the null deviance and the residual deviance shows how our model is doing against the null model
# Adding Pclass, Sex and Age significantly reduces the residual deviance, the other variables seem to improve the model less even though SibSp has a low p-value
# A large p-value here indicates that the model without the variable explains more or less the same amount of variation

pR2(model)
# While no exact equivalent to the R2 of linear regression exists, the McFadden R2 index can be used to assess the model fit

# Assess the predictivity ability of the model
fitted.results = predict(model, newdata = subset(test, select = c(2:8)), type='response') 
# By setting the parameter type='response', R will output probabilities in the form of P(y=1|X)

fitted.results = ifelse(fitted.results > 0.5, 1, 0) # here the decision boundary is set at 0.5

misClassificationError = mean(fitted.results != test$Survived)
paste('Accuracy', 1-misClassificationError) # accuracy is 0.83, however, it is somewhat dependent on the split of the data. Running cross validation can get a more precise score

# Plot the ROC curve and calculate the AUC (area under the ROC curve)
# ROC is a curve generated by plotting the true positive rate (TPR) against the FPR
# As a rule of thumb, a model with good predictive ability should have an AUC closer to 1 than to 0.5
p = predict(model, newdata = subset(test, select = c(2:8)), type='response')
pr = prediction(p, test$Survived)
prf = performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc = performance(pr, measure = 'auc')
auc = unlist(auc@y.values)
auc # auc is ~0.91
